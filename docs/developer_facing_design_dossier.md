Below is a **single, developer-facing design dossier**: it contains four complementary views that together describe the entire platform, from browser to GPU and from nightly ETL to audit dashboard.  Any engineer familiar with modern Python/JS stacks can build, operate, and extend the system from these specs alone.

---

## 1 | Physical / Deployment Diagram

```
â•‘  Browser (React) â•‘â”€â”€â”€â”€â”€â”€â”€â”€HTTPSâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ•‘  Vercel Edge Proxy  â•‘â”€â”€â”€â”€â”€â”€â–º  Railway Back-end  â”€â”
â•‘                  â•‘                      â•‘  (rewrite /api)     â•‘                          â”‚
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                          â”‚
                                                                                           â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                     â”‚                                    Gunicorn (ASGI)                  â”‚
ğŸ“¦  VPC :  Railway    â”‚   Django + DRF + Celery worker + Beat (+ Cross-Encoder in RAM)      â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚  â–²                         â”‚â–²
                Postgres     â”‚  â”‚ ORM                    Redis
           (query logs, auth)â”‚  â”‚                         â”‚ celery broker / cache
                             â”‚  â”‚                         â”‚
                             â–¼  â”‚                         â–¼
                       â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                       â•‘   Weaviate Cloud (vector + hybrid)       â•‘
                       â•‘   Class: Document (â‰ˆ 400-word chunks)    â•‘
                       â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                             â”‚                             â–²
              nightly ETL    â”‚ REST w/ vectors             â”‚ near_text search
             (Celery Beat)   â–¼                             â”‚
     bioRxiv API  â€¢  protocol PDFs  â€¢  theses PDF pipeline  â”‚
                                                       OpenAI HTTPS
                                                        (GPT-4o)
```

*All network hops TLS-encrypted; Weaviate, Postgres and Redis run in Railwayâ€™s private network; only Vercel edge exposes public HTTPS.*

---

## 2 | Detailed Component / Service Breakdown

| Component           | Tech                                              | Key Responsibilities                                                                                                                      | Scaling Knob                                |
| ------------------- | ------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------- |
| **Frontend**        | React 18 + Vite + Tailwind                        | â€¢ Chat UI & streamed answers<br>â€¢ Filter chips (All/Protocol/Paper/Thesis)<br>â€¢ Protocol upload page<br>â€¢ Confidence & citation rendering | Edge-cached static bundle; SSR not required |
| **API Layer**       | Django 4 + DRF                                    | â€¢ `/api/query/` RAG endpoint<br>â€¢ `/api/protocols/` CRUD<br>â€¢ JWT auth                                                                    | Horizontal via gunicorn workers             |
| **RAG Engine**      | Same container                                    | â€¢ 10-NN vector search via Weaviate<br>â€¢ Cross-Encoder `ms-marco-MiniLM-L-6-v2` rerank<br>â€¢ Prompt builder & policy guard rails            | Cross-Encoder kept in memory; 2â€“4 vCPU fine |
| **Task Queue**      | Celery + Redis                                    | â€¢ Nightly `fetch_biorxiv_preprints`<br>â€¢ Large-file protocol ingestion<br>â€¢ Future fine-tune jobs                                         | Add more workers if ingest >5 GB/day        |
| **Vector Store**    | Weaviate Cloud (HNSW)                             | â€¢ Stores â‰ˆ 400-word chunks w/ metadata<br>â€¢ Hybrid BM25 toggle on<br>â€¢ Multi-tenant ready                                                 | `efConstruction`, `M` tune when >1 M chunks |
| **Structured DB**   | Postgres 14                                       | â€¢ Users, QueryHistory, ThesisMeta<br>â€¢ Audit + feedback tables                                                                            | Railway Postgres 1 GB â‡’ upgrade when needed |
| **LLM Gateway**     | OpenAI GPT-4o                                     | â€¢ Completion for answers<br>â€¢ Embedding (`text-embedding-ada-002`)                                                                        | Call concurrency limited by API key QPS     |
| **Secrets & CI/CD** | Railway env-vars, Vercel env-vars, GitHub Actions | â€¢ Build â†’ test â†’ deploy manifests                                                                                                         | Add staging branch for pre-prod             |

---

## 3 | Sequence Flow (Query Path)

```mermaid
sequenceDiagram
  participant U as User (React)
  participant F as Frontend (Vercel)
  participant A as Django API
  participant V as Weaviate
  participant X as Cross-Encoder
  participant O as OpenAI

  U->>F: POST /api/query {Q, doc_type?}
  F->>A: same JWT token
  A->>V: near_text (Q) limit 10 [where doc_type?]
  V-->>A: top-10 chunks + meta
  A->>X: (Q,chunk) pairs
  X-->>A: relevance scores
  A: sort, keep top-3
  A->>O: GPT-4o prompt (Q + 3 chunks)
  O-->>A: answer text
  A->>Postgres: insert QueryHistory (Q,A,sources,conf,status)
  A-->>F: {answer, sources, conf}
  F-->>U: stream answer + citations
```

*Timeouts* â€” vector search 500 ms, rerank <100 ms, GPT 2â€“5 s.
*Guard rail* â€” if `conf < 0.45 OR no citation token`, API downgrades `status="low_confidence"` and warns front-end.

---

## 4 | Data-Ingestion Pipelines

### 4.1 Protocol / Paper

```
PDF â†’ PyMuPDF text â†’ chunk (400/100) â†’ embed (Ada-002) â†’ Weaviate {doc_type:"protocol"/"paper"}
```

### 4.2 Thesis (author-approved)

```
PDF â†’ detect CHAPTER regex â†’ chapter_split â†’ chunk 400/100
     â†’ store meta {author, year, chapter, filename, doc_type:"thesis"}
```

### 4.3 bioRxiv nightly

```
Celery beat cron â†’ bioRxiv REST window (yesterday) â†’ filter keywords
     â†’ abstract + title chunk â†’ embed â†’ Weaviate {doc_type:"paper", source:"bioRxiv"}
```

*All embeddings cached by SHA-256(document\_id + chunk\_index).*

---

## 5 | Security & Compliance

1. **Auth** â€“ JWT (`djangorestframework-simplejwt`); token forwarded by React; API checks tenant ID against vector filter.
2. **Least privilege** â€“ lab members: upload & query; only Maintainers can delete / re-index.
3. **Secrets** â€“ `.env` in Railway/Vercel; never in Git.
4. **Data privacy** â€“ raw patient data pages must be redacted before ingestion.
5. **OpenAI policy** â€“ prompt forbids export of lab IP unless citation is public.

---

## 6 | Ops & Observability

| Signal               | Where                        | Alert threshold   |
| -------------------- | ---------------------------- | ----------------- |
| API 5xx rate         | Railway metrics + Sentry     | >1 % in 5 min     |
| OpenAI latency       | custom histogram in Postgres | P95 > 15 s        |
| Celery task failures | Flower dashboard             | >2 failures / day |
| Postgres size        | Railway                      | 85 % of plan      |
| Weaviate RAM         | Cloud dashboard              | >70 % mem         |

---

## 7 | Sprint-1 Milestones (14-day Gantt)

```
D1-3   Backend RAG + Chat UI
D4     15 manual QA
D5-6   Railway + Vercel deploy
D8-10  Celery + bioRxiv fetcher
D11-12 Ingest SOPs + 1 thesis
D13    Soft-launch to 2 users
D14    Review, plan Sprint-2
```

---

## 8 | Extensibility Hooks

* **Hybrid retrieval** â€“ set `hybridSearch:true` in Weaviate or route to ElasticSearch.
* **Feedback loop** â€“ `POST /api/feedback/` â†’ nightly fine-tune cross-encoder or prompt.
* **Alternate LLM** â€“ add vLLM endpoint; in `views.py` route low-risk queries when `tokens_total < 250` and `conf >= 0.8`.
* **Graph mode** â€“ build Neo4j ingestion from SOP reagent tables â†’ graph-RAG.

---

## 8.1 | Advanced Architecture Enhancements (Post-MVP)

| Category | Enhancement | Implementation Approach | Priority |
|----------|------------|--------------------------|----------|
| **Retrieval Quality** | Hybrid Vector + BM25 Search | Fully enable Weaviate's hybrid search with proper weights tuning | High |
| | Sparse-Dense Fusion | Implement ColBERT or sparse retrieval alongside embeddings | Medium |
| | Cross-Encoder Fine-tuning | Collect user feedback to create training data for reranker | Medium |
| **Performance** | Streaming Response | Implement SSE for streaming in Django view and React | High |
| | Response Caching | Redis cache for frequently asked questions with TTL | Medium |
| | Batch Embedding Processing | Queue and process embeddings in batches to reduce API costs | Medium |
| **Resilience** | Local Model Fallback | Add Ollama with Mistral/Llama for when OpenAI is unavailable | Medium |
| | Tiered Model Selection | Route simpler queries to smaller models based on complexity | High |
| | Embedding Caching | Implement robust SHA-based embedding cache with Redis | High |
| **Quality Metrics** | User Feedback System | Add ğŸ‘/ğŸ‘ feedback buttons and comments field | High |
| | Automated Evaluation | Create test suite with golden dataset for retrieval quality | Medium |
| | Confidence Score Tuning | Improve confidence calculation with ML-based approach | Low |
| **Advanced Features** | Knowledge Graph | Extract entities from docs and build relationships in Neo4j | Medium |
| | Figure Extraction | Extract, index, and link figures from PDFs | High |
| | Multi-modal Support | Enable image queries and results where applicable | Low |

*Implementation Sequence*: Focus on high-priority items after MVP is stable, with retrieval quality improvements first, followed by performance optimizations.

---

## 9 | On-boarding checklist for new devs

1. **Clone & run** `docker-compose up -d`.
2. Create `.env` (copy sample).
3. `python manage.py createsuperuser`.
4. Run `python ingest_thesis.py sample.pdf "Test User" 2024`.
5. `npm run dev` â†’ ask a question.
6. Read `docs/DEVELOPER_NOTE.md` for edge-cases and internal conventions.

Welcome aboard!

---

*This design document together with the repo ensures the project is reproducible by any competent full-stack developer without additional oral knowledge.*
